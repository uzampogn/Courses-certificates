# Course-certificates

* <b> Accelerated - Time Series Forecasting (Instructor Led): </b>
  
  Completion date: April 2022

  The goal is to be able to analyze time series data competently and to train, evaluate and tune appropriate forecasting models to predict future points in a series. The course covers classical time series forecasting methods, including moving averages, exponential smoothing, and autoregressive methods. It also introduces modern DL approaches and existing Amazon forecasting tools. The main focus of the course is on practical applications for time series forecasting, identifying the set of suitable approaches based on data features, training methods and validation of the proposed solutions.
    
  By the end of this course students will:
    * Understand the unique challenges that the modelling of time series data poses
    * Know how to handle and prepare time series data for application of forecasting methods
    * Distinguish when a forecasting problem is suitable for a particular approach
    * Forecast using a variety of classical and modern techniques, including ETS, ARIMA, and DeepAR.

<p align="center">
  <img src="https://github.com/uzampogn/course-certificates/blob/main/MLU%20-%20Time%20Series%20Forecasting%20-%20Completion.PNG" />
</p>

* <b> Technique - Mathematical Fundamentals for Machine Learning (Instructor Led): </b>
  
  Completion date: February 2022
  
  Students will frame and solve fundamental ML business problems leveraging appropriate mathematical and statistical concepts, implementing from scratch some of the most popular ML algorithms, such as K-Nearest Neighbors, Decision Plane, Linear Regression, Logistic Regression, Naive Bayes, Principal Components Analysis, Hypothesis Testing, and Recommender System. The course covers three main mathematical and statistical areas: Linear Algebra, Differential Calculus, and Probability and Statistics. 
    
  Key competencies:
    * Identify problem types, algorithms, and metrics within an ML context, to build basic ML solutions, laying down strategies to address them using appropriate tools and techniques in a project development plan. 
    * Utilize appropriate ML software development practices, ML models and Amazon tools for the project. 


<p align="center">
  <img src="https://github.com/uzampogn/course-certificates/blob/main/MLU%20-%20Mathematical%20Fundamentals%20for%20Machine%20Learning%20-%20Completion.png" />
</p>

* <b> AWS - The Machine Learning Pipeline on AWS: </b>
  
  Completion date: April 2021
  
  This course explores how to the use of the iterative machine learning (ML) process pipeline to solve a real business problem in a project-based learning environment. Students will learn about each phase of the process pipeline from instructor presentations and demonstrations and then apply that knowledge to complete a project solving one of three business problems: fraud detection, recommendation engines, or flight delays. By the end of the course, students will have successfully built, trained, evaluated, tuned, and deployed an ML model using Amazon SageMaker that solves their selected business problem.   
  
  In this course, you will learn how to:

    * Select and justify the appropriate ML approach for a given business problem
    * Use the ML pipeline to solve a specific business problem
    * Train, evaluate, deploy, and tune an ML model in Amazon SageMaker
    * Describe some of the best practices for designing scalable, cost-optimized, and secure ML pipelines in AWS
    * Apply machine learning to a real-life business problem after the course is complete

<p align="center">
  <img src="https://github.com/uzampogn/course-certificates/blob/main/AWS%20-%20The%20Machine%20Learning%20Pipeline%20on%20AWS%20-%20Completion%20certificate.PNG" />
</p>

* <b> AWS - Big Data on AWS: </b>
  
  Completion date: March 2021
  
  This course introduces you to cloud-based big data solutions such as Amazon Elastic MapReduce (EMR), Amazon Redshift, Amazon Kinesis, and the rest of the AWS big data platform. Through this course, you learn how to use Amazon EMR to process data using the broad ecosystem of Hadoop tools like Hive and Hue. You gain a deeper understanding of how to create big data environments, work with Amazon DynamoDB, Amazon Redshift, Amazon QuickSight, Amazon Athena, and Amazon Kinesis, and leverage best practices to design big data environments for security and cost-effectiveness. 
  
  In this course, you will learn how to:

    * Utilize Amazon EMR:
    * Leverage Apache Hadoop and identify the common programming frameworks Hive, Pig, and Streaming.
    * Leverage Hue to improve the ease-of-use and Apache Spark for in-memory analytics
    * Utilize Amazon Kinesis for near real-time big data processing and Amazon Redshift to efficiently store and analyze data
    * Managing the Big Data pipeline
    * Utilize AWS Glue for Extract, Transform, & Load operations
    * Leverage Amazon Athena for ad-hoc query analytics
    * Orchestrate big data workflows using AWS Data Pipeline
    * Use visualization software to depict data and queries using Amazon QuickSight 

<p align="center">
  <img src="https://github.com/uzampogn/course-certificates/blob/main/AWS%20-%20Big%20Data%20on%20AWS%20-%20Completion%20certificate.PNG" />
</p>

* <b> AWS - Data Analytics Fundamentals: </b>
  
  Completion date: February 2021
  
  In this self-paced course, you learn about the process for planning data analysis solutions and the various data analytic processes that are involved. This course takes you through five key factors that indicate the need for specific AWS services in collecting, processing, analyzing, and presenting your data. This includes learning basic architectures, value propositions, and potential use cases. The course introduces you to the AWS services and solutions to help you build and enhance data analysis solutions.
  
  In this course, you will learn how to:

    * Identify the characteristics of data analysis solutions and the characteristics that indicate such a solution may be required
    * Define types of data including structured, semistructured, and unstructured data
    * Define data storage types such as data lakes, AWS Lake Formation, data warehouses, and the Amazon Simple Storage Service (Amazon S3)
    * Analyze the characteristics of and differences in batch and stream processing
    * Define how Amazon Kinesis is used to process streaming data
    * Analyze the characteristics of different storage systems for source data
    * Analyze the characteristics of online transaction processing (OLTP) and online analytical processing (OLAP) systems and their impact on the organization of data within these systems
    * Analyze the differences of row-based and columnar data storage methods
    * Define how Amazon EMR, AWS Glue, and Amazon Redshift each work to process, cleanse, and transform data within a data analysis solution
    * Analyze the concept of atomicity, consistency, isolation, and durability (ACID) compliance as well as basic availability, soft state, eventual consistency (BASE) compliance and how an extract,         transform, load (ETL) process can help to ensure compliance
    * Explore the concept of data schemas and understand how they define data and how this information is stored in metastores
    * Analyze the concept of data versus information
    * Recognize the ways to analyze data to produce information for reports using tools such as Amazon QuickSight and Amazon Athena
    * Define how AWS services work together to visualize data

<p align="center">
  <img src="https://github.com/uzampogn/course-certificates/blob/main/AWS%20-%20Data%20Analytics%20Fundamentals%20-%20Completion%20certificate.PNG" />
</p>
